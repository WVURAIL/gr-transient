# Jupyter Notebooks
The entire process of FRB and pulsar detection, from pulse simulation to dedispersion is simulated through the latest python document, which as of now is "Pulsar Simulator_10MHz_PSRB0329+54_second_noise_reduction_technique.ipynb". To begin, the initial parameters for the pulse are chosen. They are as follows:

* Centre Frequency: 1400MHz
* Bandwidth: 10MHz
* Frequency simulation pulse was run at: 1200MHz
* Period: .005s
* Pulse Width .0004s

These values can change, and they are up to the individual to choose.

With the pulse defined, the analogue chain is simulated. The sample rate wat which the telescope is sampling in the analogue chain is set to a sampling rate of 12GHz. An array with an amplitude of +-period and length of `sampling_rate*period` is made and is defined as `t`. This will function as the timestep for the pulse. To make the Gaussian pulse that is associated with a pulsar or FRB, a normal distribution of values that have a variance of 1 and a mean of 0 are produced. Here we are creating the pulse in a time stream first. Additionally, a Gaussian function of points is created using `G = e^{-\frac{x^2}{2*pw^2}}`, with `t` defining the values of the spread as the independent variable x , and `pw`,(the pulse width) as the variance. The two arrays, gaussian and normal, are then multiplied together to create a Gaussian distribution of points, essentially a Gaussian noise packet.

After the packet is created, all frequencies outside of our bandwidth are ignored. To do this, the FFT of the data is taken, which will give us the broadband noise that we would expect. Then a filter is used to eliminate all frequencies except for those defined within our desired bandwidth. Since our bandwidth can be defined from +-1400MHz, we will have two intervals of points that we wish to keep. All other frequencies are given an amplitude of zero, and what is left looks like two spikes,but upon closer inspection, it can be seen that these are our bandwidths. 

The IFFT of the resulting signal is taken , returning a Gaussian pulse in the time domain which is defined as `blimited_pulse`. To complete the analogue chain, IQ sampling and downsampling must also be simulated. The mixing signal that is created follows from the Euler representation of the sine mixing: `mixing_signal = np.exp(-2.00j*np.pi* Cf/sample_rate *np.arange(length))`. `Cf` is the centre frequency given in Hz, and `sample_rate` is the same as the rate defined above. It is assumed that this mixing signal is centred about 0. The pulse and the mixing signal are then multiplied together and an FFT is taken once again. Since the purpose of the mixing is to eventually downsample, a low pass filter, which is called `N_cutoff` is defined and applied to the FFT to prevent the sampled up data from being in the mixed data set that is called `f_mixed`. Finally, the data is downsampled by taking the IFFT and defining a new array which takes values from the `f_mixed` set at intervals of `sample_rate/Bw`,where Bw is the Bandwidth in Hz. This array is called `downsampled_filtered_mixed_down_s`, and the analogue chain has been completed.

If the antenna were located at the source of the pulse, this is now what the pulse would look like. This pulse however is dispersed as it travels through space, and so the simulated pulse must be dispersed as well. However before that is done, the choice of whether to simulate a pulsar or an FRB is made. If a pulsar is what is desired, then `numpy.tile` is used to create n copies of the argument and concatenate the argument and the copies. This pulsar or FRB is now dispersed by defining the number of frequency samples in the bandwidth which we call `stepfreq_step`. Using this, the time delay of the pulse or pulses is found with the equation `t = 4.15e3*DM*(v_1^-2 - v_2^2)` and will be given in units of seconds.  This delay time must also be significantly less than the dispersion time of the data. If the FFT of this is taken, and convolved with the FFT of the `downsampled_filtered_mixed_down`, the pulse\pulses are dedispersed in frequency space. The IFFT of the convolution is taken which yields the dispersed pulse. A note to be careful of: in order to achieve an FFT and IFFT without an overall gain change, it needs to be specified in the arguments of the IFFT and FFT functions that `norm='ortho'`. 

If the resulting pulse or pulse train is plotted, the pulses appear to be dispersed. To make it model a signal that would be received from an antenna, real and imaginary noise has to be added to the signal. In order to have a nice template for a matched filter, we assume noncorrelated noise is what is included with the pulse. When detecting the pulse with a matched filter, this will mean that a simple template can be used. The added noise is concatenated to the noise and signal as well which is meant to simulate looking awway from the pulsar and then looking onto the pulsar in order to get the background noise. If the concatenated arrays are plotted, depending on the amount of noise added, the concatenation boundary can be seen. However for future versions of the code, I want to implement a kurtosis or some sort of outlier elimination function. The purpose of this change would be to eliminate a dependence on a "good guess" for where to point the antenna to look for background noise. 

At this point, the data is saved as an int16 file and this is what is used as the GNUradio simulation. In order to make the most out of the file, the ratio of the maximum amplitude in the data set and the length of an int16 file is multiplied to the whole data set.

In order to ensure that the 'exact' same data is being processed in both GNUradio and the Jupyter notebook, the array that was used to create the saved file, `dispersed_downsampled_filtered_mixed_signal`, is used for the rest of the simulation. The noise is also multiplied by the same constant as the previously mentioned file. In order to see the dispersion of the pulse, this FFT of the array is taken and then integrated. The number of frequency channels is arbitrary; in the notebook, the value was set to 400 channels and labeled as `step`. The integration time for the data must be less than the pulse width of our observed pulse. So for an unknown pulsar, this amount would have to be modified to find a value less than the bandwidth. By taking `len_signal/n_freq/int_time`, the number of integrations necessary to achieve these frequency channels and integration time is found. The actual FFT is taken in a for loop and done at 400 step intervals. The FFTed array is multiplied to its complex conjugate. This process is done n times, where n is given by the `dispersed_downsampled_filtered_mixed_signal` array over the ``steps * the number of integrations``. 

It is at this point that the SNR can be estimated. Using the peak of the pulse before it was dispersed, and the variance used to create the white noise, an estimation can be made. This estimation will be used later to compare to our actual SNR. Additionally, it is at this point that we save all of the FFTed and integrated data, which I called `rec_spect`, to an int16 file, so that bench testing can be compared to the FFT and integrate blocks in GNUradio. 

`rec_spect` is then run through a function called fftshift, which shifts the frequencies so that they go from negative to positive. Additionally, the array was transposed and flipped so that time would be on the x axis of the imshow plots. The x axis ranges were also defined here using numpy.fft.fftfreq and fft.fftshift.

Now that each row of the array is in frequency space, the data is dedispersed. First the time delay, defined using the time delay equation originally used to disperse the pulse, is calculated for every frequency. Since it is being assumed that this is an unknown pulsar, a range of DMs are used to try and find the correct dispersion measure.  To shift the pulse beck to before it was dispersed, the number of bins needed to be shifted must be known. To achieve this, the change in time for each frequency is divided by the total time of the data set and the number of time bins (or time samples). This gives us a number which will allow us to know how many bins to shift. When performed for every dispersion measure, a 2D array is yielded. The array will be used as an argument in numpy.roll. It works in that given an array, is shifts it by a specified amount. So `dispersed` is called row by row, and the appropriate shift for each frequency is applied by matching the shifts per frequency in the `dispersed` and `time_change` arrays. This is repeated for every DM option tested.

The pulse is now dedispersed. To get a 2d array of DMs vs time, the sum along the frequency axis is taken. If the data is plotted with `numpy.imshow`, then a bow tie shape can be seen. The correct DM is the one that has the highest amplitude. If this data set `DM_measure` is raised to a high power like 17, then the points with a higher amplitude are drawn out with the lower points suppressed. By doing this, it can be noticed that the highest amplitude is not exactly on the correct DM. In fact, for some DMs, the correct DM sits in the middle of a bi-modal distribution, where the highest amplitudes are to either side of the correct DM. The error for these amplitudes is at most 8, so for larger DMs this is not a serious problem, which cannot be said for lower DMs. I will come back to revisit this to see if it is how the pulse was created which is causing this, or if it is the dedispersion function. 

Now that the pulse has been successfully dedispersed, I will run the detection algorithm to search for pulsars. This detection program will implement a matched filter, and the optimal filter will change depending on what noise is in the background. The noise added to the signal was white noise, meaning the optimal filter is the same shape as the pulse: a Gaussian. For non white noise, this Gaussian filter will still be used, however, as a result, the detection will be more prone to error. In the future, I will create a 3D matched filter, instead of the 2D filter being created now. This 2D filter will be created using a Gaussian with the variance of the pulse after downsampling and integration. This variance can be found with `pw/(period/packet_length)`. pw is the pulse width, which was used as the variance of the original simulated pulse. Period is the original time length of the pulse packet, which we defined conveniently as one period. Finally, packet length is defined as `int(len(downsampled_filtered_mixed_down)/step/integration_size)`. Using the definition of a Gaussian like the one to create the simulated pulse in the first place, a Gaussian pulse with the same variance of the pulses after integration is created. The length of this Gaussian pulse is defined by the packet length, which is the number of points in each pulse period.

With the filter finished, it can be cross correlated with the dedispersed data. Instead of cross correlating it by hand, the correlation can be done using `numpy.correlate`. The first two arguments of the correlation function are the data containing the pulse, and the filter. The order of the arguments must be in this order, otherwise the correlation will not be performed right. The final argument that is specified is the mode of the integration. Since the desired output array needs to have the same number of DMs as the array given to the function, the final argument is specified as `mode='same'`. 

The final step to the detection algorithm is to compute the signal to noise ratio (SNR) and to set a threshold above which any signal detected is a pulsar. The SNR is defined as `y_{av}/\sigma`where the numerator is the average value of the peaks, and sigma is the standard deviation of the background noise. Therefore, the noise that was added to the signal needs to be found. Fortunately, the noise that was concatenated to the signal + noise array was run through the same functions as the data containing pulses. This means that the noise was FFTed integrated, dedispersed, summed along the frequency axis, and convolved with the same Gaussian pulse as the data. When the noise is convolved, the final argument in the function is changed to `mode='real'`.

The mean peak amplitude is found by employing a peak finding function. This function specifically finds the peaked in a dedispersed pulsar that has been run through a matched Gaussian filter. The function takes two arguments: the array from which the peaks will be found from, and the threshold above which points can be classified as peaks. The array used for the data must have at least two dimensions, where the first is the DM being tested, and the second is the number of data points. Additionally, `len(threshold)` must be equal to `len(DMs)`, since the threshold should change slightly for each DM. The function begins by using a for loop with a range of length of the first dimension of `correlates`. This dimension should be the same size as the number of DMs being tried. The function then calls another for loop with a range of one less than the length of the time samples. Each point in the correlated data is now checked to see if it satisfies the criteria of a local maximum. That is all nearby points must be smaller in amplitude than the surrounding points. If the data point being checked satisfies this criteria, then the amplitude of the point is saved in a list. When the function terminates, it should return a list with size of ''number of DMs'' by ''number of peaks''. 

The average of the peaks for each DM is computed and these values are taken as the mean peak height for each DM: `y_{av}`. Next the std and mean of the noise are calculated. This is done bu simply applying `numpy.std` and `numpy.mean` to the correlated noise. To get the true y_{av}, the mean of the noise is subtracted from the mean peaks. This is then divided by the standard deviation as detailed in the SNR equation above. The signal to noise ratio has now been calculated, and it has been determined that if is above 10, for more than five data points, then a pulsar of FRB has been detected. This is to ensure that with higher amplitude, non white noise, stray signals will not be mistaken for a pulsar.